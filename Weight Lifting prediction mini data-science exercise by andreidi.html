<!DOCTYPE html>
<!-- saved from url=(0051)https://andreidi.github.io/WeightLiftingPrediction/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <link href="./Weight Lifting prediction mini data-science exercise by andreidi_files/css" rel="stylesheet" type="text/css">
    <link rel="stylesheet" type="text/css" href="./Weight Lifting prediction mini data-science exercise by andreidi_files/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="./Weight Lifting prediction mini data-science exercise by andreidi_files/github-dark.css" media="screen">
    <link rel="stylesheet" type="text/css" href="./Weight Lifting prediction mini data-science exercise by andreidi_files/print.css" media="print">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <title>Weight Lifting prediction mini data-science exercise by andreidi</title>
  </head>

  <body>
    <div id="container">
      <div class="inner">

        <header>
          <h1>Weight Lifting prediction mini data-science exercise</h1>
          <h2>Practical Machine Learning Write-up for predictions based on Weight Lifting Exercise Dataset</h2>
        </header>

        <section id="downloads" class="clearfix">
          <a href="https://github.com/andreidi/WeightLiftingPrediction/zipball/master" id="download-zip" class="button"><span>Download .zip</span></a>
          <a href="https://github.com/andreidi/WeightLiftingPrediction/tarball/master" id="download-tar-gz" class="button"><span>Download .tar.gz</span></a>
          <a href="https://github.com/andreidi/WeightLiftingPrediction" id="view-on-github" class="button"><span>View on GitHub</span></a>
        </section>

        <hr>

        <section id="main_content">
          <h1>
<a id="practical-machine-learning-course-project-weight-lifting-prediction" class="anchor" href="https://andreidi.github.io/WeightLiftingPrediction/#practical-machine-learning-course-project-weight-lifting-prediction" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Practical Machine Learning Course Project: Weight Lifting prediction</h1>

<p>Author: Andrei Ionut Damian, email: <a href="mailto:damian@cloudifier.net">damian@cloudifier.net</a></p>

<h2>
<a id="the-short-description" class="anchor" href="https://andreidi.github.io/WeightLiftingPrediction/#the-short-description" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>The Short description</h2>

<p>This page presents my whole approach for solving Practical Machine Learning Course Exercise from Johns Hopkins University Data Science Specialization on Coursera. Data Science and Practical Machine Learning creators are: 
<strong>Roger D. Peng</strong>, PhD, Associate Professor, Biostatistics; <strong>Brian Caffo</strong>, PhD, Professor, Biostatistics; <strong>Jeff Leek</strong>, PhD, Associate Professor, Biostatistics.
In this script I have used a specific approach for data exploration and cleaning and also my specific approach for model selection, training, cross-validation and finally testing. </p>

<h3>
<a id="note-some-steps-both-in-data-explorationcleaning-and-model-training-could-have-been-omitted-from-this-final-transcript-of-my-work-however-i-decided-to-include-everything-to-present-the-approach-the-order-of-the-steps-the-logical-conclusions-i-derived-from-each-step---even-if-some-of-those-steps-along-the-way-have-become-partially-or-totally-obsolete" class="anchor" href="https://andreidi.github.io/WeightLiftingPrediction/#note-some-steps-both-in-data-explorationcleaning-and-model-training-could-have-been-omitted-from-this-final-transcript-of-my-work-however-i-decided-to-include-everything-to-present-the-approach-the-order-of-the-steps-the-logical-conclusions-i-derived-from-each-step---even-if-some-of-those-steps-along-the-way-have-become-partially-or-totally-obsolete" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Note: Some steps both in data exploration/cleaning and model training could have been omitted from this final "transcript" of my work, however I decided to include everything to present the approach, the order of the steps, the logical conclusions I derived from each step - even if some of those steps along the way have become partially or totally obsolete.</h3>

<h2>
<a id="the-background" class="anchor" href="https://andreidi.github.io/WeightLiftingPrediction/#the-background" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>The Background</h2>

<p>This text is based on Coursera presentation of the present Data Science exercise:
<em>Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: <a href="http://groupware.les.inf.puc-rio.br/har">http://groupware.les.inf.puc-rio.br/har</a> (see the section on the Weight Lifting Exercise Dataset)</em>.</p>

<h2>
<a id="the-approach" class="anchor" href="https://andreidi.github.io/WeightLiftingPrediction/#the-approach" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>The approach</h2>

<h2>
<a id="for-data-exploration" class="anchor" href="https://andreidi.github.io/WeightLiftingPrediction/#for-data-exploration" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>For data exploration:</h2>

<ul>
<li>  clean useless (useless in regard to prediction) data columns such as index, person names, etc</li>
<li>  clean <strong>NA data predictor</strong> variables</li>
<li>  clean <strong>empty data</strong> predictor variables</li>
<li>  near <strong>zero variance predictor</strong> variables</li>
<li>  predictor <strong>variables correlation</strong> analysis (pair feature plot excluded for this case)</li>
<li>  analyze <strong>variables importance</strong> based on Recursive Feature Elimination and choose best selection</li>
</ul>

<h2>
<a id="for-model-preparation-selection-cross-validation" class="anchor" href="https://andreidi.github.io/WeightLiftingPrediction/#for-model-preparation-selection-cross-validation" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>For model preparation, selection, cross-validation</h2>

<ul>
<li>  from initial training dataset three subsets are generated: training, cross-validation and testing</li>
<li>  <strong>optional</strong> PCA is used to pre-process training data then PCA model is used to fit cross/testing</li>
<li>  there is option to either use or not PCA as well as use or not the automated selected features: for final run I chosed not to use PCA and used automate selected features (based on RFE)</li>
<li>  a <strong>list</strong> of models is used in a automated/iterative process</li>
<li>  each model is <strong>cross</strong> evaluated including running time</li>
</ul>

<h2>
<a id="code-sections" class="anchor" href="https://andreidi.github.io/WeightLiftingPrediction/#code-sections" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Code sections</h2>

<p>Begin with loading <code>caret</code> and also <code>parallel</code> processing so we can use all cores in order to speed up all the heavy computing tasks:</p>

<div class="highlight highlight-source-r"><pre><span class="pl-smi">avail_cores</span> <span class="pl-k">&lt;-</span> detectCores() 
<span class="pl-smi">p_cluster</span> <span class="pl-k">&lt;-</span> makeCluster(<span class="pl-smi">avail_cores</span>)
registerDoParallel(<span class="pl-smi">p_cluster</span>)
sprintf(<span class="pl-s"><span class="pl-pds">"</span>Cores registered = %d<span class="pl-pds">"</span></span>,getDoParWorkers())</pre></div>

<pre><code>## [1] "Cores registered = 8"
</code></pre>

<h2>
<a id="loading-and-cleaning" class="anchor" href="https://andreidi.github.io/WeightLiftingPrediction/#loading-and-cleaning" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>LOADING AND CLEANING</h2>

<p>To start we have to identify current script working directory then load all data in data exploration dataframe <code>exploreData</code> and make a copy in <code>finalData</code> that will be used later on for final cleaning process.</p>

<div class="highlight highlight-source-r"><pre><span class="pl-smi">exploreData</span> <span class="pl-k">&lt;-</span> read.csv(<span class="pl-s"><span class="pl-pds">"</span>pml-training.csv<span class="pl-pds">"</span></span>)
<span class="pl-smi">finalData</span> <span class="pl-k">&lt;-</span> <span class="pl-k">data.frame</span>(<span class="pl-smi">exploreData</span>)</pre></div>

<p>First lets do a quick analysis of zero variance predictors with <code>nearZeroVar(exploreData, saveMetrics = TRUE)</code>. We will display the total amount of near-zero variance predictors and the head of the table containing them. We are going to maintain a list of <code>ALL DROPPED COLUMNS</code> in order to use it for the final test dataset pre-processing (together with the PCA model if any).</p>

<pre><code>## [1] "Total number of to-be-dropped near-zero var features = 60"

##                       freqRatio percentUnique zeroVar  nzv
## new_window             47.33005    0.01019264   FALSE TRUE
## kurtosis_yaw_belt      47.33005    0.01019264   FALSE TRUE
## skewness_yaw_belt      47.33005    0.01019264   FALSE TRUE
## kurtosis_yaw_dumbbell  47.33005    0.01019264   FALSE TRUE
## skewness_yaw_dumbbell  47.33005    0.01019264   FALSE TRUE
## kurtosis_yaw_forearm   47.33005    0.01019264   FALSE TRUE
</code></pre>

<p>Now it is obvious we have a lot of <strong>cleaning</strong> to do on data so we need to start the data exploration and cleaning process - first drop totally useless columns such as observation number, name and then start working on the NA columns, find if there are NA-only columns or columns with more than 95% NA, get na column indexes then finally get the actual column names and display them:</p>

<pre><code>## [1] "Number of NA columns to-be-dropped = 67"

##  [1] "max_roll_belt"            "max_picth_belt"          
##  [3] "min_roll_belt"            "min_pitch_belt"          
##  [5] "amplitude_roll_belt"      "amplitude_pitch_belt"    
##  [7] "var_total_accel_belt"     "avg_roll_belt"           
##  [9] "stddev_roll_belt"         "var_roll_belt"           
## [11] "avg_pitch_belt"           "stddev_pitch_belt"       
## [13] "var_pitch_belt"           "avg_yaw_belt"            
## [15] "stddev_yaw_belt"          "var_yaw_belt"            
## [17] "var_accel_arm"            "avg_roll_arm"            
## [19] "stddev_roll_arm"          "var_roll_arm"            
## [21] "avg_pitch_arm"            "stddev_pitch_arm"        
## [23] "var_pitch_arm"            "avg_yaw_arm"             
## [25] "stddev_yaw_arm"           "var_yaw_arm"             
## [27] "max_roll_arm"             "max_picth_arm"           
## [29] "max_yaw_arm"              "min_roll_arm"            
## [31] "min_pitch_arm"            "min_yaw_arm"             
## [33] "amplitude_roll_arm"       "amplitude_pitch_arm"     
## [35] "amplitude_yaw_arm"        "max_roll_dumbbell"       
## [37] "max_picth_dumbbell"       "min_roll_dumbbell"       
## [39] "min_pitch_dumbbell"       "amplitude_roll_dumbbell" 
## [41] "amplitude_pitch_dumbbell" "var_accel_dumbbell"      
## [43] "avg_roll_dumbbell"        "stddev_roll_dumbbell"    
## [45] "var_roll_dumbbell"        "avg_pitch_dumbbell"      
## [47] "stddev_pitch_dumbbell"    "var_pitch_dumbbell"      
## [49] "avg_yaw_dumbbell"         "stddev_yaw_dumbbell"     
## [51] "var_yaw_dumbbell"         "max_roll_forearm"        
## [53] "max_picth_forearm"        "min_roll_forearm"        
## [55] "min_pitch_forearm"        "amplitude_roll_forearm"  
## [57] "amplitude_pitch_forearm"  "var_accel_forearm"       
## [59] "avg_roll_forearm"         "stddev_roll_forearm"     
## [61] "var_roll_forearm"         "avg_pitch_forearm"       
## [63] "stddev_pitch_forearm"     "var_pitch_forearm"       
## [65] "avg_yaw_forearm"          "stddev_yaw_forearm"      
## [67] "var_yaw_forearm"
</code></pre>

<p>Now get columns that are actually <strong>empty</strong> (actually similar to na - more than <strong>95% empty</strong>), display all of them and finally perform cleaning on dataset:</p>

<pre><code>## [1] "Number of Empty columns dropped = 33"

##  [1] "kurtosis_roll_belt"      "kurtosis_picth_belt"    
##  [3] "kurtosis_yaw_belt"       "skewness_roll_belt"     
##  [5] "skewness_roll_belt.1"    "skewness_yaw_belt"      
##  [7] "max_yaw_belt"            "min_yaw_belt"           
##  [9] "amplitude_yaw_belt"      "kurtosis_roll_arm"      
## [11] "kurtosis_picth_arm"      "kurtosis_yaw_arm"       
## [13] "skewness_roll_arm"       "skewness_pitch_arm"     
## [15] "skewness_yaw_arm"        "kurtosis_roll_dumbbell" 
## [17] "kurtosis_picth_dumbbell" "kurtosis_yaw_dumbbell"  
## [19] "skewness_roll_dumbbell"  "skewness_pitch_dumbbell"
## [21] "skewness_yaw_dumbbell"   "max_yaw_dumbbell"       
## [23] "min_yaw_dumbbell"        "amplitude_yaw_dumbbell" 
## [25] "kurtosis_roll_forearm"   "kurtosis_picth_forearm" 
## [27] "kurtosis_yaw_forearm"    "skewness_roll_forearm"  
## [29] "skewness_pitch_forearm"  "skewness_yaw_forearm"   
## [31] "max_yaw_forearm"         "min_yaw_forearm"        
## [33] "amplitude_yaw_forearm"
</code></pre>

<h3>
<a id="predictors-variance-and-correlation-analysis" class="anchor" href="https://andreidi.github.io/WeightLiftingPrediction/#predictors-variance-and-correlation-analysis" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Predictors variance and correlation analysis</h3>

<p>The next step in building our model, after basic cleaning is to analyze again the predictors variance using <code>nearZeroVar</code>. Then we will sort and display the predictors with least variance and also display all factor variables and their summary omitting the label <code>classe</code>. Finally we drop the factor variables with near-zero variance:</p>

<pre><code>## [1] "Near zero variance table:"

##                      freqRatio percentUnique zeroVar   nzv
## new_window           47.330049    0.01019264   FALSE  TRUE
## classe                1.469581    0.02548160   FALSE FALSE
## total_accel_belt      1.063160    0.14779329   FALSE FALSE
## total_accel_dumbbell  1.072634    0.21914178   FALSE FALSE
## total_accel_arm       1.024526    0.33635715   FALSE FALSE
## gyros_belt_y          1.144000    0.35164611   FALSE FALSE

## [1] "Factors variables to be dropped:" "new_window"

##  new_window 
##  no :19216  
##  yes:  406
</code></pre>

<h2>
<a id="variable-correlation-analysis" class="anchor" href="https://andreidi.github.io/WeightLiftingPrediction/#variable-correlation-analysis" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Variable correlation analysis</h2>

<p>Now analyze the predictor variables correlation in order determine if we have very high correlation. We do this by calculating correlation matrix with <code>cor(exploreData[,setdiff(colnames(exploreData),c("classe"))])</code> (excluding label <code>classe</code> column):</p>

<pre><code>##  [1] "Highly correlated predictor variables:"
##  [2] "accel_belt_z"                          
##  [3] "roll_belt"                             
##  [4] "accel_belt_y"                          
##  [5] "accel_arm_y"                           
##  [6] "total_accel_belt"                      
##  [7] "accel_dumbbell_z"                      
##  [8] "accel_belt_x"                          
##  [9] "pitch_belt"                            
## [10] "magnet_dumbbell_x"                     
## [11] "accel_dumbbell_y"                      
## [12] "magnet_dumbbell_y"                     
## [13] "accel_arm_x"                           
## [14] "accel_dumbbell_x"                      
## [15] "accel_arm_z"                           
## [16] "magnet_arm_y"                          
## [17] "magnet_belt_z"                         
## [18] "accel_forearm_y"                       
## [19] "gyros_dumbbell_x"                      
## [20] "gyros_forearm_y"                       
## [21] "gyros_dumbbell_z"                      
## [22] "gyros_arm_x"
</code></pre>

<p>Due to high correlation between variable we might need to apply PCA later or use a feature selection methods available in the <code>caret</code> package</p>

<h3>
<a id="recursive-feature-elimination-step" class="anchor" href="https://andreidi.github.io/WeightLiftingPrediction/#recursive-feature-elimination-step" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Recursive Feature Elimination Step</h3>

<p>Finally in data cleaning and pre-processing stage we analyze the actual variables importance based on a trained model and obtain a automatic features selection model based on <code>rfe</code> available within <code>caret</code> package.We will get two samples of our data and then train two different <code>rfe</code> models based on random forests followed by plot view/analysis on both. First plot of number of features vs cross-validation accuracy:</p>

<p><img src="./Weight Lifting prediction mini data-science exercise by andreidi_files/fig1.png" alt=""></p>

<p>And now the second plot of predictor variables quantity vs prediction accuracy:</p>

<p><img src="./Weight Lifting prediction mini data-science exercise by andreidi_files/fig2.png" alt=""></p>

<p>Based on the two plots it is obvious that best number of predictors is between 5 and 12. Now we combine our findings in order to obtain a final list of predictor variables:</p>

<pre><code>## [1] "FINAL PREDICTORS :" "roll_belt"          "num_window"        
## [4] "magnet_dumbbell_z"  "pitch_forearm"      "magnet_dumbbell_y"
</code></pre>

<h2>
<a id="training-and-testing-models" class="anchor" href="https://andreidi.github.io/WeightLiftingPrediction/#training-and-testing-models" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>TRAINING AND TESTING MODELS</h2>

<p>Finally we can now prepare training, cross-validation and test datasets (training dataset 60%, crossval dataset 20%, testing dataset 20%), but first having the list of all <code>dropped_columns</code> we can either apply it to <code>finalData</code> or we could use the automated selection of predictor variables. Based on this, we have a few special meta-parameters for customizing our model: - <code>useAutomaticPredictors</code> controls if we use or not the short list of predictors generated by <strong>Recursive Feature Elimination</strong> - <code>usePCA</code> controls if we use or not dimensionality reduction preprocessing based on <strong>Principal Components Analysis</strong></p>

<div class="highlight highlight-source-r"><pre><span class="pl-v">useAutomaticPredictors</span> <span class="pl-k">=</span> <span class="pl-c1">TRUE</span>
<span class="pl-v">usePCA</span> <span class="pl-k">=</span> <span class="pl-c1">FALSE</span>

<span class="pl-k">if</span> (<span class="pl-smi">useAutomaticPredictors</span>){
  <span class="pl-smi">good_columns</span> <span class="pl-k">&lt;-</span> c(<span class="pl-smi">final_predictors</span>,c(<span class="pl-s"><span class="pl-pds">"</span>classe<span class="pl-pds">"</span></span>))
  <span class="pl-smi">pred_columns</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">final_predictors</span> 
}<span class="pl-k">else</span>{
  <span class="pl-smi">good_columns</span> <span class="pl-k">&lt;-</span> setdiff(colnames(<span class="pl-smi">finalData</span>), <span class="pl-smi">dropped_columns</span>)
  <span class="pl-smi">pred_columns</span> <span class="pl-k">&lt;-</span> setdiff(<span class="pl-smi">good_columns</span>, c(<span class="pl-s"><span class="pl-pds">"</span>classe<span class="pl-pds">"</span></span>))

}

<span class="pl-smi">finalData</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">finalData</span>[<span class="pl-smi">good_columns</span>]
<span class="pl-smi">inTraining</span> <span class="pl-k">&lt;-</span> createDataPartition(<span class="pl-smi">finalData</span><span class="pl-k">$</span><span class="pl-smi">classe</span>, <span class="pl-v">p</span><span class="pl-k">=</span><span class="pl-c1">0.6</span>, <span class="pl-v">list</span><span class="pl-k">=</span><span class="pl-c1">FALSE</span>)
<span class="pl-smi">trainingStd</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">finalData</span>[<span class="pl-smi">inTraining</span>,]
<span class="pl-smi">testdataStd</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">finalData</span>[<span class="pl-k">-</span><span class="pl-smi">inTraining</span>,]
<span class="pl-smi">inVal</span> <span class="pl-k">&lt;-</span> createDataPartition(<span class="pl-smi">testdataStd</span><span class="pl-k">$</span><span class="pl-smi">classe</span>, <span class="pl-v">p</span><span class="pl-k">=</span><span class="pl-c1">0.5</span>, <span class="pl-v">list</span><span class="pl-k">=</span><span class="pl-c1">FALSE</span>)
<span class="pl-smi">crossvalStd</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">testdataStd</span>[<span class="pl-smi">inVal</span>,]
<span class="pl-smi">testingStd</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">testdataStd</span>[<span class="pl-k">-</span><span class="pl-smi">inVal</span>,]
<span class="pl-c">##</span>
<span class="pl-c">## Now the PCA pre-processing stage (if needed)</span>
<span class="pl-c">##</span>
<span class="pl-k">if</span> (<span class="pl-smi">usePCA</span>)
{
  <span class="pl-smi">PCA.model</span> <span class="pl-k">&lt;-</span> preProcess(<span class="pl-smi">trainingStd</span>[<span class="pl-smi">pred_columns</span>],<span class="pl-v">method</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>pca<span class="pl-pds">"</span></span>, <span class="pl-v">thresh</span><span class="pl-k">=</span><span class="pl-c1">0.95</span>)
  <span class="pl-smi">training</span> <span class="pl-k">&lt;-</span> predict(<span class="pl-smi">PCA.model</span>, <span class="pl-smi">trainingStd</span>)
  <span class="pl-smi">crossvalidation</span> <span class="pl-k">&lt;-</span> predict(<span class="pl-smi">PCA.model</span>,<span class="pl-smi">crossvalStd</span> )
  <span class="pl-smi">testing</span> <span class="pl-k">&lt;-</span> predict(<span class="pl-smi">PCA.model</span>, <span class="pl-smi">testingStd</span>)  
} <span class="pl-k">else</span>
{
  <span class="pl-smi">training</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">trainingStd</span>
  <span class="pl-smi">crossvalidation</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">crossvalStd</span>
  <span class="pl-smi">testing</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">testingStd</span>
}</pre></div>

<h2>
<a id="multi-model-cross-validation-testing" class="anchor" href="https://andreidi.github.io/WeightLiftingPrediction/#multi-model-cross-validation-testing" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Multi-model cross-validation testing</h2>

<p>Now I train several different models, analyze them and then and then choose the best model based on best cross validation score. So first stage is timed training for each proposed model and cross-validations. Keep all accuracy values in vectors then combine in dataframe to finally display.</p>

<div class="highlight highlight-source-r"><pre><span class="pl-smi">All.Methods</span> <span class="pl-k">&lt;-</span> c(<span class="pl-s"><span class="pl-pds">"</span>lda<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>rpart<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>knn<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>lvq<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>xgbTree<span class="pl-pds">"</span></span>)
<span class="pl-smi">nr_models</span> <span class="pl-k">&lt;-</span> length(<span class="pl-smi">All.Methods</span>)
<span class="pl-smi">Cross.Accuracy</span> <span class="pl-k">&lt;-</span> c()
<span class="pl-smi">Training.Time</span> <span class="pl-k">&lt;-</span> c()
<span class="pl-smi">bestAccuracy</span> <span class="pl-k">&lt;-</span> <span class="pl-c1">0</span> 

<span class="pl-k">for</span> (<span class="pl-smi">c_model</span> <span class="pl-k">in</span> <span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-smi">nr_models</span>){

  <span class="pl-smi">methodName</span> <span class="pl-k">&lt;-</span>  <span class="pl-smi">All.Methods</span>[<span class="pl-smi">c_model</span>]
  print(paste0(<span class="pl-s"><span class="pl-pds">"</span>Training <span class="pl-pds">"</span></span>,<span class="pl-smi">methodName</span>,<span class="pl-s"><span class="pl-pds">"</span>...<span class="pl-pds">"</span></span>))
  <span class="pl-smi">tmr_start</span> <span class="pl-k">&lt;-</span> proc.time()
  <span class="pl-smi">curr.model</span> <span class="pl-k">&lt;-</span> train(<span class="pl-smi">classe</span> <span class="pl-k">~</span> .,
                      <span class="pl-v">data</span> <span class="pl-k">=</span> <span class="pl-smi">training</span>,
                      <span class="pl-v">method</span> <span class="pl-k">=</span> <span class="pl-smi">methodName</span>)
  <span class="pl-smi">tmr_end</span> <span class="pl-k">&lt;-</span> proc.time()
  print(paste0(<span class="pl-s"><span class="pl-pds">"</span>Done training <span class="pl-pds">"</span></span>,<span class="pl-smi">methodName</span>,<span class="pl-s"><span class="pl-pds">"</span>.<span class="pl-pds">"</span></span>))  
  <span class="pl-smi">Training.Time</span>[<span class="pl-smi">c_model</span>] <span class="pl-k">=</span> (<span class="pl-smi">tmr_end</span><span class="pl-k">-</span><span class="pl-smi">tmr_start</span>)[<span class="pl-c1">3</span>]

  <span class="pl-smi">preds</span><span class="pl-k">&lt;-</span> predict(<span class="pl-smi">curr.model</span>,<span class="pl-smi">crossvalidation</span>)

  <span class="pl-smi">cfm</span> <span class="pl-k">&lt;-</span> confusionMatrix(<span class="pl-smi">preds</span>,<span class="pl-smi">crossvalStd</span><span class="pl-k">$</span><span class="pl-smi">classe</span>)
  <span class="pl-smi">Cross.Accuracy</span>[<span class="pl-smi">c_model</span>] <span class="pl-k">&lt;-</span> <span class="pl-smi">cfm</span><span class="pl-k">$</span><span class="pl-smi">overall</span>[<span class="pl-s"><span class="pl-pds">'</span>Accuracy<span class="pl-pds">'</span></span>]

  <span class="pl-k">if</span>(<span class="pl-smi">bestAccuracy</span> <span class="pl-k">&lt;</span> <span class="pl-smi">Cross.Accuracy</span>[<span class="pl-smi">c_model</span>]){
    <span class="pl-smi">best.model</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">curr.model</span>
    <span class="pl-smi">bestAccuracy</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">Cross.Accuracy</span>[<span class="pl-smi">c_model</span>]
  }

}</pre></div>

<pre><code>## [1] "Training lda..."

## Loading required package: MASS

## [1] "Done training lda."
## [1] "Training rpart..."

## Loading required package: rpart

## [1] "Done training rpart."
## [1] "Training knn..."
## [1] "Done training knn."
## [1] "Training lvq..."

## Loading required package: class

## [1] "Done training lvq."
## [1] "Training xgbTree..."

## Loading required package: xgboost

## Loading required package: plyr

## [1] "Done training xgbTree."
</code></pre>

<p>And the custom constructed summary of the training and cross-validation process:</p>

<pre><code>##   All.Methods Cross.Accuracy Training.Time
## 1         lda      0.3907724          0.91
## 4         lvq      0.5281672         46.55
## 2       rpart      0.5388733          1.28
## 3         knn      0.9548815          7.24
## 5     xgbTree      0.9994902        175.94
</code></pre>

<h3>
<a id="almost-there-" class="anchor" href="https://andreidi.github.io/WeightLiftingPrediction/#almost-there-" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Almost there !</h3>

<p>Now that we have our final model lets apply it on testing dataset and then display confusion matrix so we can visually compare test result with previous cross validation one. We could also use a random forest or other classifier to ensemble to 2 or 3 predictors. Nevertheless this is not needed for this particular exercise as <em><strong>top two predictors achieved over 95% accuracy</strong></em> with the best one constantly over 99% with a out-of-sample error rate of under 1% based on cross-validation dataset (used for all predictors) and the second test dataset (used only for best model).</p>

<pre><code>## [1] "Predicting with best predictor: xgbTree"

## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1113    0    0    0    0
##          B    0  759    0    0    0
##          C    1    0  684    0    0
##          D    0    0    0  643    0
##          E    2    0    0    0  721
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9992          
##                  95% CI : (0.9978, 0.9998)
##     No Information Rate : 0.2845          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.999           
##  Mcnemar's Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9973   1.0000   1.0000   1.0000   1.0000
## Specificity            1.0000   1.0000   0.9997   1.0000   0.9994
## Pos Pred Value         1.0000   1.0000   0.9985   1.0000   0.9972
## Neg Pred Value         0.9989   1.0000   1.0000   1.0000   1.0000
## Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838
## Detection Rate         0.2837   0.1935   0.1744   0.1639   0.1838
## Detection Prevalence   0.2837   0.1935   0.1746   0.1639   0.1843
## Balanced Accuracy      0.9987   1.0000   0.9998   1.0000   0.9997
</code></pre>

<h2>
<a id="final-step" class="anchor" href="https://andreidi.github.io/WeightLiftingPrediction/#final-step" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Final step</h2>

<p>Now finally apply best model on unseen observation. <em>Note: xGBoost model constantly achieved over 99% accuracy on all cross-validation testing pointing to a out-of-sample error rate under 1%</em>:</p>

<pre><code>## [1] "Now predicting unseen observations with: xgbTree"

##  [1] B A B A A E D * * * * * * * * * * * * *
## Levels: A B C D E
</code></pre>

<p><em><strong>Please note I partially masked the final prediction in order not to bias other students and/or violate Coursera Honor Code.</strong></em></p>
        </section>

        <footer>
          Weight Lifting prediction mini data-science exercise is maintained by <a href="https://github.com/andreidi">andreidi</a><br>
          This page was generated by <a href="https://pages.github.com/">GitHub Pages</a>. Tactile theme by <a href="https://twitter.com/jasonlong">Jason Long</a>.
        </footer>

        
      </div>
    </div>
  

</body></html>